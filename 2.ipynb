{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import matplotlib.pyplot as  plt\n",
    "from sklearn import tree\n",
    "import plotly\n",
    "import plotly.offline as pyoff\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.graph_objs as go\n",
    "%matplotlib inline\n",
    "\n",
    "MENS = 'mens'\n",
    "WOMENS = 'womens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train-1542197608821.csv\")\n",
    "test_data = pd.read_csv(\"test-1542197608821.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Types of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * There are 0 NA's in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.info()\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()\n",
    "\n",
    "#outcome column not present in test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hitpoint', 'outside.sideline', 'outside.baseline', 'same.side', 'previous.hitpoint', 'server.is.impact.player', 'outcome', 'gender']\n"
     ]
    }
   ],
   "source": [
    "# Columns in Data With Categorical Values- Must LabelEncode them\n",
    "categorical_cols = ['hitpoint', 'outside.sideline', 'outside.baseline', 'same.side', \n",
    "                    'previous.hitpoint', 'server.is.impact.player','outcome','gender']\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serve', 'rally', 'speed', 'net.clearance', 'distance.from.sideline', 'depth', 'player.distance.travelled', 'player.impact.depth', 'player.impact.distance.from.center', 'player.depth', 'player.distance.from.center', 'previous.speed', 'previous.net.clearance', 'previous.distance.from.sideline', 'previous.depth', 'opponent.depth', 'opponent.distance.from.center', 'previous.time.to.net']\n"
     ]
    }
   ],
   "source": [
    "# Columns in the Data That Should Be Scaled\n",
    "scaled_data = ['serve','rally', 'speed', 'net.clearance', 'distance.from.sideline', 'depth', 'player.distance.travelled', \n",
    "               'player.impact.depth', 'player.impact.distance.from.center', 'player.depth', \n",
    "               'player.distance.from.center', 'previous.speed', 'previous.net.clearance', \n",
    "               'previous.distance.from.sideline', 'previous.depth', 'opponent.depth', \n",
    "               'opponent.distance.from.center', 'previous.time.to.net']\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing One hot Encoder on tain and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " D: defaultdict(<class 'sklearn.preprocessing.label.LabelEncoder'>, {})\n",
      "\n",
      "train[categorical_cols]:\n",
      "       hitpoint  outside.sideline  outside.baseline  same.side  \\\n",
      "0            0                 0                 0          1   \n",
      "1            0                 0                 1          0   \n",
      "2            0                 0                 0          0   \n",
      "3            1                 1                 0          1   \n",
      "4            0                 0                 0          0   \n",
      "5            0                 1                 0          1   \n",
      "6            0                 0                 1          0   \n",
      "7            1                 0                 0          0   \n",
      "8            1                 0                 1          0   \n",
      "9            1                 0                 0          1   \n",
      "10           1                 1                 1          0   \n",
      "11           0                 0                 1          0   \n",
      "12           0                 1                 0          0   \n",
      "13           1                 0                 1          0   \n",
      "14           1                 0                 1          1   \n",
      "15           2                 0                 0          0   \n",
      "16           1                 0                 0          1   \n",
      "17           1                 0                 0          0   \n",
      "18           1                 0                 0          1   \n",
      "19           1                 0                 0          0   \n",
      "20           1                 1                 0          0   \n",
      "21           1                 0                 1          0   \n",
      "22           0                 0                 0          0   \n",
      "23           1                 0                 1          0   \n",
      "24           2                 0                 1          0   \n",
      "25           3                 0                 0          0   \n",
      "26           0                 0                 1          0   \n",
      "27           1                 0                 1          0   \n",
      "28           1                 0                 0          0   \n",
      "29           1                 0                 0          1   \n",
      "...        ...               ...               ...        ...   \n",
      "7971         0                 0                 0          1   \n",
      "7972         0                 0                 0          0   \n",
      "7973         0                 0                 1          0   \n",
      "7974         1                 1                 1          1   \n",
      "7975         1                 0                 0          0   \n",
      "7976         0                 0                 0          0   \n",
      "7977         0                 1                 0          0   \n",
      "7978         0                 1                 0          0   \n",
      "7979         1                 0                 0          1   \n",
      "7980         0                 1                 0          0   \n",
      "7981         1                 0                 0          0   \n",
      "7982         1                 0                 0          1   \n",
      "7983         0                 1                 0          1   \n",
      "7984         0                 0                 0          0   \n",
      "7985         1                 1                 0          1   \n",
      "7986         1                 0                 1          0   \n",
      "7987         1                 1                 1          0   \n",
      "7988         0                 1                 0          0   \n",
      "7989         0                 0                 0          0   \n",
      "7990         1                 1                 0          0   \n",
      "7991         0                 0                 0          1   \n",
      "7992         0                 0                 0          0   \n",
      "7993         1                 1                 0          0   \n",
      "7994         1                 0                 0          0   \n",
      "7995         1                 0                 0          0   \n",
      "7996         1                 0                 0          0   \n",
      "7997         0                 0                 1          0   \n",
      "7998         1                 0                 0          0   \n",
      "7999         1                 0                 0          0   \n",
      "8000         1                 0                 0          0   \n",
      "\n",
      "      previous.hitpoint  server.is.impact.player  outcome  gender  \n",
      "0                     1                        0        1       0  \n",
      "1                     0                        0        0       0  \n",
      "2                     1                        1        0       0  \n",
      "3                     0                        1        1       0  \n",
      "4                     1                        0        2       0  \n",
      "5                     1                        0        1       0  \n",
      "6                     1                        1        1       0  \n",
      "7                     1                        1        2       0  \n",
      "8                     3                        1        1       0  \n",
      "9                     1                        0        2       0  \n",
      "10                    1                        1        0       0  \n",
      "11                    0                        1        1       0  \n",
      "12                    1                        1        1       0  \n",
      "13                    1                        0        1       0  \n",
      "14                    1                        1        1       0  \n",
      "15                    1                        1        1       0  \n",
      "16                    1                        1        1       0  \n",
      "17                    1                        1        2       0  \n",
      "18                    3                        1        2       0  \n",
      "19                    3                        1        2       0  \n",
      "20                    1                        0        0       0  \n",
      "21                    2                        1        1       0  \n",
      "22                    1                        1        2       0  \n",
      "23                    1                        0        0       0  \n",
      "24                    2                        0        1       0  \n",
      "25                    1                        0        2       0  \n",
      "26                    0                        1        1       0  \n",
      "27                    1                        1        1       0  \n",
      "28                    0                        1        2       0  \n",
      "29                    3                        1        2       0  \n",
      "...                 ...                      ...      ...     ...  \n",
      "7971                  0                        0        0       1  \n",
      "7972                  1                        1        1       1  \n",
      "7973                  1                        0        1       1  \n",
      "7974                  1                        0        1       1  \n",
      "7975                  0                        1        2       1  \n",
      "7976                  1                        0        2       1  \n",
      "7977                  0                        0        1       1  \n",
      "7978                  0                        0        1       1  \n",
      "7979                  3                        1        2       1  \n",
      "7980                  0                        0        1       1  \n",
      "7981                  1                        0        2       1  \n",
      "7982                  3                        1        2       1  \n",
      "7983                  1                        1        0       1  \n",
      "7984                  0                        1        1       1  \n",
      "7985                  1                        0        0       1  \n",
      "7986                  1                        0        1       1  \n",
      "7987                  1                        1        0       1  \n",
      "7988                  0                        0        0       1  \n",
      "7989                  0                        0        2       1  \n",
      "7990                  0                        1        1       1  \n",
      "7991                  0                        0        2       1  \n",
      "7992                  0                        1        2       1  \n",
      "7993                  0                        1        1       1  \n",
      "7994                  1                        0        2       1  \n",
      "7995                  1                        0        0       1  \n",
      "7996                  1                        0        2       1  \n",
      "7997                  1                        1        1       1  \n",
      "7998                  0                        0        2       1  \n",
      "7999                  0                        0        2       1  \n",
      "8000                  0                        1        1       1  \n",
      "\n",
      "[8001 rows x 8 columns]\n",
      "\n",
      "temp_Outcome: ['hitpoint', 'outside.sideline', 'outside.baseline', 'same.side', 'previous.hitpoint', 'server.is.impact.player', 'outcome', 'gender']\n",
      "\n",
      " E: defaultdict(<class 'sklearn.preprocessing.label.LabelEncoder'>, {'hitpoint': LabelEncoder(), 'outside.sideline': LabelEncoder(), 'outside.baseline': LabelEncoder(), 'same.side': LabelEncoder(), 'previous.hitpoint': LabelEncoder(), 'server.is.impact.player': LabelEncoder(), 'gender': LabelEncoder()})\n",
      "\n",
      " test[temp]:       hitpoint  outside.sideline  outside.baseline  same.side  \\\n",
      "0            1                 0                 0          1   \n",
      "1            1                 0                 0          0   \n",
      "2            0                 1                 1          1   \n",
      "3            1                 0                 0          1   \n",
      "4            1                 0                 1          0   \n",
      "5            2                 1                 0          0   \n",
      "6            0                 0                 0          0   \n",
      "7            0                 0                 0          0   \n",
      "8            1                 0                 0          1   \n",
      "9            1                 0                 0          0   \n",
      "10           0                 0                 0          0   \n",
      "11           0                 0                 0          1   \n",
      "12           1                 0                 0          0   \n",
      "13           1                 0                 0          0   \n",
      "14           1                 0                 1          0   \n",
      "15           0                 0                 0          0   \n",
      "16           0                 0                 0          0   \n",
      "17           1                 0                 0          0   \n",
      "18           1                 1                 0          0   \n",
      "19           1                 1                 0          0   \n",
      "20           1                 0                 0          0   \n",
      "21           0                 0                 0          0   \n",
      "22           1                 1                 0          1   \n",
      "23           0                 0                 0          0   \n",
      "24           1                 0                 1          0   \n",
      "25           1                 0                 0          0   \n",
      "26           1                 0                 0          0   \n",
      "27           1                 0                 0          0   \n",
      "28           1                 1                 0          0   \n",
      "29           1                 0                 0          0   \n",
      "...        ...               ...               ...        ...   \n",
      "1969         1                 0                 0          1   \n",
      "1970         0                 1                 0          0   \n",
      "1971         0                 0                 1          0   \n",
      "1972         0                 0                 1          0   \n",
      "1973         1                 0                 0          0   \n",
      "1974         2                 0                 0          1   \n",
      "1975         1                 0                 1          1   \n",
      "1976         1                 0                 0          0   \n",
      "1977         1                 0                 0          0   \n",
      "1978         0                 0                 0          0   \n",
      "1979         0                 0                 1          1   \n",
      "1980         1                 0                 0          1   \n",
      "1981         1                 0                 1          1   \n",
      "1982         1                 0                 1          0   \n",
      "1983         1                 0                 0          0   \n",
      "1984         0                 0                 0          1   \n",
      "1985         0                 0                 0          1   \n",
      "1986         1                 0                 0          1   \n",
      "1987         0                 0                 1          1   \n",
      "1988         0                 0                 1          0   \n",
      "1989         1                 0                 0          1   \n",
      "1990         0                 0                 0          0   \n",
      "1991         1                 1                 0          0   \n",
      "1992         1                 0                 0          1   \n",
      "1993         0                 1                 1          1   \n",
      "1994         0                 0                 0          0   \n",
      "1995         1                 1                 0          0   \n",
      "1996         1                 0                 0          0   \n",
      "1997         0                 0                 0          1   \n",
      "1998         1                 0                 0          0   \n",
      "\n",
      "      previous.hitpoint  server.is.impact.player  gender  \n",
      "0                     1                        1       0  \n",
      "1                     1                        0       0  \n",
      "2                     1                        0       0  \n",
      "3                     1                        1       0  \n",
      "4                     1                        1       0  \n",
      "5                     2                        1       0  \n",
      "6                     1                        0       0  \n",
      "7                     1                        0       0  \n",
      "8                     1                        0       0  \n",
      "9                     0                        1       0  \n",
      "10                    1                        1       0  \n",
      "11                    1                        0       0  \n",
      "12                    0                        1       0  \n",
      "13                    0                        0       0  \n",
      "14                    1                        1       0  \n",
      "15                    0                        1       0  \n",
      "16                    0                        1       0  \n",
      "17                    0                        1       0  \n",
      "18                    0                        1       0  \n",
      "19                    1                        0       0  \n",
      "20                    0                        1       0  \n",
      "21                    0                        0       0  \n",
      "22                    1                        1       0  \n",
      "23                    0                        1       0  \n",
      "24                    3                        0       0  \n",
      "25                    1                        1       0  \n",
      "26                    1                        1       0  \n",
      "27                    0                        1       0  \n",
      "28                    1                        1       0  \n",
      "29                    0                        0       0  \n",
      "...                 ...                      ...     ...  \n",
      "1969                  0                        0       1  \n",
      "1970                  0                        0       1  \n",
      "1971                  1                        1       1  \n",
      "1972                  1                        0       1  \n",
      "1973                  1                        1       1  \n",
      "1974                  0                        0       1  \n",
      "1975                  0                        0       1  \n",
      "1976                  1                        0       1  \n",
      "1977                  1                        0       1  \n",
      "1978                  1                        1       1  \n",
      "1979                  1                        0       1  \n",
      "1980                  3                        0       1  \n",
      "1981                  0                        1       1  \n",
      "1982                  0                        1       1  \n",
      "1983                  1                        0       1  \n",
      "1984                  0                        0       1  \n",
      "1985                  3                        1       1  \n",
      "1986                  3                        0       1  \n",
      "1987                  1                        1       1  \n",
      "1988                  0                        1       1  \n",
      "1989                  1                        1       1  \n",
      "1990                  0                        0       1  \n",
      "1991                  0                        1       1  \n",
      "1992                  0                        0       1  \n",
      "1993                  1                        1       1  \n",
      "1994                  0                        0       1  \n",
      "1995                  1                        1       1  \n",
      "1996                  1                        1       1  \n",
      "1997                  1                        1       1  \n",
      "1998                  0                        1       1  \n",
      "\n",
      "[1999 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def encode(train, test):\n",
    "    # Retain All LabelEncoder as a dictionary\n",
    "    d = defaultdict(LabelEncoder)\n",
    "    print(\"\\n D:\",d)\n",
    "\n",
    "    # Encode all the columns\n",
    "    train[categorical_cols] = train[categorical_cols].apply(lambda x: d[x.name].fit_transform(x))\n",
    "    print(\"\\ntrain[categorical_cols]:\\n\",train[categorical_cols])\n",
    "#     test[categorical_cols] = train[categorical_cols].apply(lambda x: d[x.name].fit_transform(x))\n",
    "    test_ids = test['ID']\n",
    "    # Inverse the encoding\n",
    "    # data.apply(lambda x: d[x.name].inverse_transform(x))\n",
    "    \n",
    "    # Using dictionary d to label future data\n",
    "    temp = deepcopy(categorical_cols)\n",
    "    print(\"\\ntemp_Outcome:\",temp)\n",
    "    temp.remove('outcome')\n",
    "    e = deepcopy(d)\n",
    "    del e['outcome']\n",
    "    print(\"\\n E:\",e)\n",
    "#     for key in e.keys():\n",
    "#         print(key)\n",
    "#         print(e[key].classes_)\n",
    "#     print(temp)\n",
    "    \n",
    "    test[temp] = test[temp].apply(lambda x: e[x.name].transform(x))\n",
    "    print(\"\\n test[temp]:\",test[temp])\n",
    "    # #     print(d['hitpoint'].classes_)\n",
    "    train = train.drop(['ID'], axis=1)\n",
    "    test = test.drop(['ID'], axis=1)\n",
    "    \n",
    "    #print(\"\\n train:{}, test:{}, test_ids:{}, d:{}\", train, test, test_ids, d)\n",
    "    return train, test, test_ids, d\n",
    "\n",
    "#outcome = data['outcome']\n",
    "#print(\"\\nOutcome:\",outcome)\n",
    "data, test_data, test_ids , d = encode(data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "#X_train,X_val,y_train,y_val = train_test_split(data test_size=0.3)\n",
    "#print(X_train.shape, X_val.shape,y_train.shape,y_val.shape)\n",
    "train_X, val_X = train_test_split(data, test_size=0.2)\n",
    "X_train = train_X.loc[:, train_X.columns != 'outcome']\n",
    "y_train = train_X['outcome']\n",
    "X_val = val_X.loc[:, val_X.columns != 'outcome']\n",
    "y_val = val_X['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "Accuracy: 69.8042%\n",
      "Log Loss: 2.0148601913129367\n",
      "==============================\n",
      "SVC\n",
      "****Results****\n",
      "Accuracy: 84.2982%\n",
      "Log Loss: 0.443930107407962\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 80.1749%\n",
      "Log Loss: 6.847337594326316\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 83.9234%\n",
      "Log Loss: 0.9162891174631701\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 83.4236%\n",
      "Log Loss: 1.0481995504516184\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 86.8805%\n",
      "Log Loss: 0.344588862558353\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 74.5106%\n",
      "Log Loss: 1.3165871232414625\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(7),\n",
    "    SVC(kernel=\"poly\", C=0.025, probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_val)\n",
    "    acc = accuracy_score(y_val, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "    train_predictions = clf.predict_proba(X_val)\n",
    "    ll = log_loss(y_val, train_predictions)\n",
    "    print(\"Log Loss: {}\".format(ll))\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.4453%\n",
      "Log Loss: 0.3558452983366544\n"
     ]
    }
   ],
   "source": [
    "gb_model_m = GradientBoostingClassifier(n_jobs=4,n_estimators=150, learning_rate=0.1, max_depth=4, min_samples_leaf=6)  #with n_estimators set to default Accuracy: 87.6952% Log Loss: 0.33349268494880946\n",
    "#Grid search result (learning_rate = 0.1, max_depth= 6, min_samples_leaf= 20, n_estimators= 200)\n",
    "gb_model_m.fit(X_train, y_train.ravel())\n",
    "val_prob_prediction = gb_model_m.predict_proba(X_val)\n",
    "val_prediction = gb_model_m.predict(X_val)\n",
    "acc = accuracy_score(y_val, val_prediction)\n",
    "print(\"Accuracy: {:.4%}\".format(acc))\n",
    "ll = log_loss(y_val, val_prob_prediction)\n",
    "print(\"Log Loss: {}\".format(ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.6731%\n",
      "Log Loss: 0.4284354495592927\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel=\"poly\", C=0.01, probability=True)\n",
    "svc_model.fit(X_train,y_train)\n",
    "svc_prob_prediction = svc_model.predict_proba(X_val)\n",
    "svc_val_prediction = svc_model.predict(X_val)\n",
    "svc_acc = accuracy_score(y_val, svc_val_prediction)\n",
    "print(\"Accuracy: {:.4%}\".format(svc_acc))\n",
    "svc_loss = log_loss(y_val, svc_prob_prediction)\n",
    "print(\"Log Loss: {}\".format(svc_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.5885%\n",
      "Log Loss: 0.3738272755654149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\BULLET\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning:\n",
      "\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbc_model = XGBClassifier(n_estimators=250, learning_rate=0.1, max_depth=7, min_samples_leaf=20)\n",
    "xgbc_model.fit(X_train, y_train)\n",
    "xgbc_prob_pred = xgbc_model.predict_proba(X_val)\n",
    "xgbc_pred = xgbc_model.predict(X_val)\n",
    "xgbc_loss = log_loss(y_val, xgbc_prob_pred)\n",
    "xgbc_acc = accuracy_score(y_val, xgbc_pred)\n",
    "print(\"Accuracy: {:.4%}\".format(xgbc_acc))\n",
    "print(\"Log Loss: {}\".format(xgbc_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.7139%\n",
      "Log Loss: 0.3778797520867165\n"
     ]
    }
   ],
   "source": [
    "rfclf_model = RandomForestClassifier(n_jobs=-1,n_estimators=500, random_state=0) \n",
    "rfclf_model.fit(X_train, y_train)\n",
    "rfclf_prob_pred = rfclf_model.predict_proba(X_val)\n",
    "rfclf_pred = rfclf_model.predict(X_val)\n",
    "rfclf_loss = log_loss(y_val, rfclf_prob_pred)\n",
    "rfclf_acc = accuracy_score(y_val, rfclf_pred)\n",
    "print(\"Accuracy: {:.4%}\".format(rfclf_acc))\n",
    "print(\"Log Loss: {}\".format(rfclf_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Forrest test data predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 ... 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "rfclf_prob_prediction = rfclf_model.predict_proba(test_data)\n",
    "rfclf_val_prediction = rfclf_model.predict(test_data)\n",
    "print(rfclf_val_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n"
     ]
    }
   ],
   "source": [
    "print(rfclf_val_prediction.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'UE', 'FE', 'W', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'W', 'W', 'UE', 'W', 'W', 'W', 'W', 'FE', 'UE', 'FE', 'UE', 'W', 'W', 'W', 'FE', 'FE', 'UE', 'UE', 'FE', 'W', 'W', 'W', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'FE', 'W', 'UE', 'W', 'W', 'W', 'FE', 'FE', 'UE', 'FE', 'UE', 'UE', 'FE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'UE', 'FE', 'W', 'FE', 'FE', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'FE', 'UE', 'FE', 'UE', 'W', 'FE', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'FE', 'FE', 'UE', 'W', 'W', 'FE', 'W', 'UE', 'W', 'W', 'W', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'W', 'W', 'W', 'FE', 'UE', 'FE', 'W', 'W', 'FE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'UE', 'FE', 'UE', 'FE', 'FE', 'FE', 'FE', 'FE', 'W', 'UE', 'W', 'W', 'W', 'FE', 'FE', 'FE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'FE', 'UE', 'W', 'FE', 'FE', 'UE', 'FE', 'UE', 'FE', 'W', 'FE', 'W', 'W', 'FE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'W', 'FE', 'FE', 'W', 'W', 'FE', 'FE', 'W', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'FE', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'FE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'W', 'W', 'W', 'FE', 'FE', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'FE', 'W', 'FE', 'UE', 'UE', 'FE', 'W', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'UE', 'W', 'W', 'UE', 'W', 'W', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'FE', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'UE', 'W', 'FE', 'FE', 'FE', 'W', 'UE', 'W', 'W', 'W', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'FE', 'W', 'W', 'UE', 'UE', 'FE', 'UE', 'W', 'UE', 'W', 'W', 'W', 'UE', 'FE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'UE', 'FE', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'FE', 'FE', 'W', 'W', 'W', 'W', 'FE', 'UE', 'UE', 'FE', 'W', 'W', 'W', 'FE', 'UE', 'UE', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'FE', 'W', 'FE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'W', 'FE', 'W', 'FE', 'W', 'W', 'FE', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'W', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'FE', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'UE', 'FE', 'FE', 'W', 'UE', 'FE', 'FE', 'FE', 'FE', 'FE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'FE', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'W', 'FE', 'W', 'W', 'W', 'FE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'W', 'W', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'FE', 'FE', 'FE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'W', 'W', 'W', 'FE', 'W', 'W', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'FE', 'W', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'W', 'W', 'FE', 'FE', 'UE', 'UE', 'UE', 'FE', 'W', 'UE', 'FE', 'UE', 'W', 'FE', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'FE', 'FE', 'W', 'FE', 'W', 'UE', 'FE', 'W', 'W', 'W', 'W', 'W', 'UE', 'W', 'UE', 'FE', 'W', 'UE', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'FE', 'W', 'W', 'FE', 'UE', 'UE', 'W', 'W', 'FE', 'W', 'FE', 'UE', 'W', 'W', 'UE', 'FE', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'UE', 'FE', 'W', 'FE', 'FE', 'FE', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'UE', 'FE', 'UE', 'FE', 'W', 'W', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'UE', 'W', 'FE', 'UE', 'FE', 'W', 'W', 'UE', 'FE', 'W', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'W', 'FE', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'FE', 'W', 'W', 'UE', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'FE', 'FE', 'FE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'UE', 'FE', 'UE', 'UE', 'FE', 'FE', 'FE', 'W', 'UE', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'UE', 'FE', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'FE', 'W', 'FE', 'FE', 'FE', 'UE', 'FE', 'W', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'FE', 'W', 'FE', 'FE', 'UE', 'UE', 'W', 'W', 'W', 'UE', 'FE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'W', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'FE', 'W', 'W', 'W', 'UE', 'UE', 'FE', 'W', 'UE', 'W', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'UE', 'FE', 'W', 'UE', 'FE', 'UE', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'UE', 'FE', 'UE', 'FE', 'FE', 'W', 'UE', 'W', 'UE', 'FE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'FE', 'FE', 'W', 'FE', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'FE', 'FE', 'W', 'UE', 'W', 'UE', 'FE', 'FE', 'W', 'W', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'W', 'UE', 'W', 'UE', 'FE', 'W', 'UE', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'W', 'FE', 'FE', 'UE', 'W', 'FE', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'W', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'W', 'FE', 'W', 'FE', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'W', 'FE', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'W', 'FE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'W', 'W', 'FE', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'FE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'FE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'UE', 'UE', 'FE', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'W', 'FE', 'W', 'W', 'W', 'FE', 'UE', 'UE', 'W', 'FE', 'FE', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'W', 'FE', 'UE', 'UE', 'W', 'FE', 'UE', 'FE', 'FE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'FE', 'W', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'FE', 'UE', 'FE', 'FE', 'W', 'UE', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'W', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'FE', 'FE', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'UE', 'W', 'FE', 'UE', 'W', 'UE', 'W', 'W', 'FE', 'FE', 'UE', 'W', 'W', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'FE', 'UE', 'FE', 'FE', 'W', 'FE', 'W', 'UE', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'FE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'FE', 'UE', 'FE', 'UE', 'W', 'W', 'FE', 'FE', 'UE', 'UE', 'FE', 'UE', 'W', 'W', 'FE', 'UE', 'W', 'FE', 'FE', 'FE', 'UE', 'UE', 'FE', 'UE', 'FE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'W', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'FE', 'W', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'W', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'UE', 'FE', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'W', 'FE', 'W', 'FE', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'FE', 'W', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'W', 'W', 'FE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'FE', 'W', 'UE', 'FE', 'UE', 'W', 'FE', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'W', 'W', 'W', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'W', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'FE', 'W', 'W', 'W', 'W', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'W', 'W', 'FE', 'W', 'UE', 'W', 'FE', 'W', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'FE', 'FE', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'FE', 'FE', 'W', 'UE', 'UE', 'FE', 'FE', 'UE', 'W', 'UE', 'UE', 'W', 'W', 'FE', 'W', 'W', 'W', 'FE', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'FE', 'FE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'W', 'UE', 'W', 'FE', 'UE', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'W', 'UE', 'W', 'W', 'W', 'W', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'FE', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'FE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'W', 'UE', 'FE', 'W', 'FE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'FE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W']\n"
     ]
    }
   ],
   "source": [
    "rfclf_test_val = rfclf_val_prediction\n",
    "outcome = []\n",
    "#test_val_prediction = test_val_prediction.astype(np.char)\n",
    "for i in range(0,len(rfclf_val_prediction)):\n",
    "    if rfclf_val_prediction[i] == 0:\n",
    "        outcome.append('FE')\n",
    "    elif rfclf_val_prediction[i] == 1:\n",
    "        outcome.append('UE')\n",
    "    else :\n",
    "        outcome.append('W')\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 ... 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "test_prob_prediction = gb_model_m.predict_proba(test_data)\n",
    "test_val_prediction = gb_model_m.predict(test_data)\n",
    "print(test_val_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1921\n",
      "1        486\n",
      "2       5177\n",
      "3       4632\n",
      "4       2735\n",
      "5       6843\n",
      "6       7756\n",
      "7       3053\n",
      "8       9605\n",
      "9       5662\n",
      "10       930\n",
      "11       313\n",
      "12      6070\n",
      "13      6207\n",
      "14      7468\n",
      "15      7814\n",
      "16      1039\n",
      "17      8476\n",
      "18      5931\n",
      "19      5280\n",
      "20      4575\n",
      "21      6082\n",
      "22      6234\n",
      "23      3410\n",
      "24      6918\n",
      "25      5034\n",
      "26      3379\n",
      "27      2425\n",
      "28      1240\n",
      "29      8575\n",
      "        ... \n",
      "1969    5668\n",
      "1970     885\n",
      "1971    2821\n",
      "1972    3853\n",
      "1973    8946\n",
      "1974    4293\n",
      "1975    8786\n",
      "1976    9204\n",
      "1977    5174\n",
      "1978    9580\n",
      "1979    5073\n",
      "1980    1638\n",
      "1981    5074\n",
      "1982    8677\n",
      "1983    3248\n",
      "1984    1650\n",
      "1985    9945\n",
      "1986    4711\n",
      "1987    6561\n",
      "1988    3945\n",
      "1989    4017\n",
      "1990    8969\n",
      "1991     681\n",
      "1992    2023\n",
      "1993    9321\n",
      "1994    9081\n",
      "1995    1281\n",
      "1996    1169\n",
      "1997    2374\n",
      "1998     311\n",
      "Name: ID, Length: 1999, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'UE', 'FE', 'W', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'W', 'W', 'UE', 'W', 'W', 'W', 'W', 'FE', 'UE', 'FE', 'UE', 'W', 'W', 'W', 'FE', 'FE', 'UE', 'UE', 'FE', 'W', 'W', 'W', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'FE', 'W', 'UE', 'W', 'W', 'W', 'FE', 'FE', 'UE', 'FE', 'UE', 'UE', 'FE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'UE', 'FE', 'W', 'FE', 'FE', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'FE', 'UE', 'FE', 'UE', 'W', 'FE', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'FE', 'FE', 'UE', 'W', 'W', 'FE', 'W', 'UE', 'W', 'W', 'W', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'W', 'W', 'W', 'FE', 'UE', 'FE', 'W', 'W', 'FE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'UE', 'FE', 'UE', 'FE', 'FE', 'FE', 'FE', 'FE', 'W', 'UE', 'W', 'W', 'W', 'FE', 'FE', 'FE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'FE', 'UE', 'W', 'FE', 'FE', 'UE', 'FE', 'UE', 'FE', 'W', 'FE', 'W', 'W', 'FE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'W', 'FE', 'FE', 'W', 'W', 'FE', 'FE', 'W', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'FE', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'FE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'W', 'W', 'W', 'FE', 'FE', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'FE', 'W', 'FE', 'UE', 'UE', 'FE', 'W', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'UE', 'W', 'W', 'UE', 'W', 'W', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'FE', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'UE', 'W', 'FE', 'FE', 'FE', 'W', 'UE', 'W', 'W', 'W', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'FE', 'W', 'W', 'UE', 'UE', 'FE', 'UE', 'W', 'UE', 'W', 'W', 'W', 'UE', 'FE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'UE', 'FE', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'FE', 'FE', 'W', 'W', 'W', 'W', 'FE', 'UE', 'UE', 'FE', 'W', 'W', 'W', 'FE', 'UE', 'UE', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'FE', 'W', 'FE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'W', 'FE', 'W', 'FE', 'W', 'W', 'FE', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'W', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'FE', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'UE', 'FE', 'FE', 'W', 'UE', 'FE', 'FE', 'FE', 'FE', 'FE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'FE', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'W', 'FE', 'W', 'W', 'W', 'FE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'W', 'W', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'FE', 'FE', 'FE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'W', 'W', 'W', 'FE', 'W', 'W', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'FE', 'W', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'W', 'W', 'FE', 'FE', 'UE', 'UE', 'UE', 'FE', 'W', 'UE', 'FE', 'UE', 'W', 'FE', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'FE', 'FE', 'W', 'FE', 'W', 'UE', 'FE', 'W', 'W', 'W', 'W', 'W', 'UE', 'W', 'UE', 'FE', 'W', 'UE', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'FE', 'W', 'W', 'FE', 'UE', 'UE', 'W', 'W', 'FE', 'W', 'FE', 'UE', 'W', 'W', 'UE', 'FE', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'UE', 'FE', 'W', 'FE', 'FE', 'FE', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'UE', 'FE', 'UE', 'FE', 'W', 'W', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'UE', 'W', 'FE', 'UE', 'FE', 'W', 'W', 'UE', 'FE', 'W', 'UE', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'W', 'FE', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'FE', 'W', 'W', 'UE', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'FE', 'FE', 'FE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'UE', 'FE', 'UE', 'UE', 'FE', 'FE', 'FE', 'W', 'UE', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'UE', 'FE', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'FE', 'W', 'FE', 'FE', 'FE', 'UE', 'FE', 'W', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'FE', 'W', 'FE', 'FE', 'UE', 'UE', 'W', 'W', 'W', 'UE', 'FE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'W', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'FE', 'W', 'W', 'W', 'UE', 'UE', 'FE', 'W', 'UE', 'W', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'UE', 'FE', 'W', 'UE', 'FE', 'UE', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'UE', 'FE', 'UE', 'FE', 'FE', 'W', 'UE', 'W', 'UE', 'FE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'FE', 'FE', 'W', 'FE', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'FE', 'FE', 'W', 'UE', 'W', 'UE', 'FE', 'FE', 'W', 'W', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'W', 'UE', 'W', 'UE', 'FE', 'W', 'UE', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'W', 'FE', 'FE', 'UE', 'W', 'FE', 'UE', 'W', 'W', 'W', 'W', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'W', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'W', 'FE', 'W', 'FE', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'FE', 'FE', 'W', 'W', 'FE', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'W', 'FE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'W', 'W', 'FE', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'FE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'FE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'UE', 'UE', 'FE', 'W', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'W', 'FE', 'W', 'W', 'W', 'FE', 'UE', 'UE', 'W', 'FE', 'FE', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'UE', 'W', 'FE', 'UE', 'UE', 'W', 'FE', 'UE', 'FE', 'FE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'FE', 'W', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'FE', 'UE', 'FE', 'FE', 'W', 'UE', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'W', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'FE', 'FE', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'UE', 'W', 'FE', 'UE', 'W', 'UE', 'W', 'W', 'FE', 'FE', 'UE', 'W', 'W', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'FE', 'UE', 'FE', 'FE', 'W', 'FE', 'W', 'UE', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'FE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'FE', 'UE', 'FE', 'UE', 'W', 'W', 'FE', 'FE', 'UE', 'UE', 'FE', 'UE', 'W', 'W', 'FE', 'UE', 'W', 'FE', 'FE', 'FE', 'UE', 'UE', 'FE', 'UE', 'FE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'W', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'FE', 'W', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'FE', 'FE', 'UE', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'W', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'UE', 'FE', 'UE', 'FE', 'UE', 'W', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'FE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'W', 'FE', 'W', 'FE', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'FE', 'W', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'W', 'FE', 'W', 'UE', 'W', 'W', 'FE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'FE', 'W', 'UE', 'FE', 'UE', 'W', 'FE', 'UE', 'FE', 'UE', 'FE', 'W', 'UE', 'W', 'W', 'W', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'W', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'UE', 'FE', 'W', 'W', 'W', 'W', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'W', 'W', 'FE', 'W', 'UE', 'W', 'FE', 'W', 'W', 'W', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'FE', 'FE', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'FE', 'FE', 'W', 'UE', 'UE', 'FE', 'FE', 'UE', 'W', 'UE', 'UE', 'W', 'W', 'FE', 'W', 'W', 'W', 'FE', 'FE', 'UE', 'UE', 'W', 'W', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'FE', 'UE', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'W', 'W', 'FE', 'UE', 'UE', 'UE', 'FE', 'FE', 'UE', 'UE', 'UE', 'FE', 'FE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'W', 'FE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'W', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'W', 'UE', 'W', 'FE', 'UE', 'FE', 'UE', 'W', 'W', 'W', 'UE', 'W', 'UE', 'W', 'W', 'W', 'W', 'FE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'FE', 'FE', 'W', 'W', 'UE', 'UE', 'UE', 'FE', 'FE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'UE', 'FE', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'W', 'UE', 'FE', 'W', 'FE', 'UE', 'W', 'W', 'UE', 'W', 'UE', 'FE', 'W', 'W', 'UE', 'UE', 'W', 'W', 'FE', 'UE', 'UE', 'W', 'W', 'W', 'UE', 'UE', 'W', 'W', 'UE', 'FE', 'UE', 'W', 'UE', 'W', 'UE', 'W', 'W', 'UE', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'UE', 'FE', 'W', 'W', 'UE', 'UE', 'W', 'UE', 'UE', 'FE', 'UE', 'W', 'UE', 'UE', 'UE', 'W']\n"
     ]
    }
   ],
   "source": [
    "test_val = test_val_prediction\n",
    "outcome = []\n",
    "#test_val_prediction = test_val_prediction.astype(np.char)\n",
    "for i in range(0,len(test_val_prediction)):\n",
    "    if test_val_prediction[i] == 0:\n",
    "        outcome.append('FE')\n",
    "    elif test_val_prediction[i] == 1:\n",
    "        outcome.append('UE')\n",
    "    else :\n",
    "        outcome.append('W')\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     outcome\n",
      "ID          \n",
      "1921       W\n",
      "486       UE\n",
      "5177      FE\n",
      "4632       W\n",
      "2735      UE\n",
      "6843      FE\n",
      "7756      UE\n",
      "3053      FE\n",
      "9605       W\n",
      "5662      UE\n",
      "930       UE\n",
      "313        W\n",
      "6070       W\n",
      "6207       W\n",
      "7468      UE\n",
      "7814      UE\n",
      "1039      UE\n",
      "8476       W\n",
      "5931      UE\n",
      "5280      FE\n",
      "4575       W\n",
      "6082      UE\n",
      "6234      UE\n",
      "3410       W\n",
      "6918      FE\n",
      "5034       W\n",
      "3379       W\n",
      "2425       W\n",
      "1240      UE\n",
      "8575       W\n",
      "...      ...\n",
      "5668       W\n",
      "885       UE\n",
      "2821      UE\n",
      "3853      UE\n",
      "8946       W\n",
      "4293      UE\n",
      "8786      UE\n",
      "9204      FE\n",
      "5174       W\n",
      "9580      UE\n",
      "5073      UE\n",
      "1638       W\n",
      "5074      UE\n",
      "8677      UE\n",
      "3248      UE\n",
      "1650      FE\n",
      "9945       W\n",
      "4711       W\n",
      "6561      UE\n",
      "3945      UE\n",
      "4017       W\n",
      "8969      UE\n",
      "681       UE\n",
      "2023      FE\n",
      "9321      UE\n",
      "9081       W\n",
      "1281      UE\n",
      "1169      UE\n",
      "2374      UE\n",
      "311        W\n",
      "\n",
      "[1999 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame(outcome, index=test_ids)\n",
    "submission.columns = ['outcome']\n",
    "print(submission)\n",
    "submission.to_csv(\"final_submission_6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
